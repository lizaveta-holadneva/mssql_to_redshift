import pyodbc
import psycopg2
import time
import math

# connect to msSQL
server = 'ec2-63-33-209-197.eu-west-1.compute.amazonaws.com'
database = 'CURINGNOVEMBER'
username = 'sa'
password = 'apollo-mssql-hs8kslllf9376hns'


class DatabaseRequest:

    #initialization and connection
    def __init__(self):
        try:
            self.conn1 = pyodbc.connect(
                'Driver={ODBC Driver 17 for SQL Server};SERVER=' + server + ';DATABASE=' + database + ';UID=' + username + ';PWD=' + password)
            self.conn2 = psycopg2.connect(
                "dbname='curingnovember' user='awsuser' password='UaxnkKo2vncVisDxZN1r' host='manufacturing-datawarehouse.cckei3etycxh.eu-west-1.redshift.amazonaws.com' port='5439'")
            self.cur1 = self.conn1.cursor()
            self.cur2 = self.conn2.cursor()
            self.table_name = 'tbl2'
        except Exception as e:
            print("there is an error in initialization: " + str(e))
    
    def create_table(self):
        #https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_TABLE_NEW.html
        #az64 - This encoding results in significant storage savings in most cases relative to LZO and ZSTD encodings and optimal de-compression performance for numeric and date/time data stored in Amazon Redshift.
        #double precision(FLOAT8) - floating point standard representation requires a 64 bit word, which may be represented as numbered from 0 to 63, left to right.
        #BIGINT(INT8),An IDENTITY column contains unique autogenerated values. The data type for an IDENTITY column must be either INT or BIGINT. To be sure that the identity values are unique, Amazon Redshift skips a number of values when creating the identity values. Identity values are unique, but the order might not match the order in the source files. If no default value is specified, the default value for the column is null.
        self.cur2.execute("CREATE TABLE IF NOT EXISTS tbl2 (id varchar(256), valueid integer encode az64, timestamp timestamp encode az64,realvalue double precision,hist_id BIGINT IDENTITY NOT NULL);")
        self.conn2.commit()

    #executing, fetching, writing to db and deleting duplicates
    def proc(self):
        #CONCAT() function adds two or more strings together.
        #convert(varchar, getdate(), 121)	2006-12-30 00:38:54.840
        self.cur1.execute("SELECT concat(replace(ValueID, ' ', ''), '_',  convert(varchar,Timestamp,121), '000'), ValueID, Timestamp, RealValue FROM Table_uncompressed")
        #time to finish the loop. %.2f stands for format 0.01. "%s seconds" 	 0.764891862869 seconds
        print(" %.2f executed" % (time.time() - start_time))

        fetch_per_one_step = 10000   #step size for fetching. changed from 1,000,000 to 10,000
        chunk_size = 1500  #step size for writing to db. changed from 150,000 to 1,500

        try:
            while True:
                rows = self.cur1.fetchmany(fetch_per_one_step)
                if not rows:
                    break
                print(" %.2f fetched" % (time.time() - start_time))
                #logic to split and write data to db. data_size = 1000000
                data_size = len(rows)
                #math.ceil(x). Return the ceiling of x as a float, the smallest integer value greater than or equal to x.
                #chunk_count=7. Data is splitted by 7 parts. 7*150000=1050000
                chunk_count = math.ceil(data_size / chunk_size)

                for x in range(chunk_count):
                    #take chunk_size data rows. data from 0 to 1, data from 1 to 2 etc.
                    chunk_part = rows[x * chunk_size:(x + 1) * chunk_size]
                    print('adding from ' + str(x) + ' part to ' + str(x + 1) + ' part')
                    #write_data - stores data
                    self.write_data(self.cur2, self.conn2, chunk_part)
                    print(str(len(chunk_part)) + ' added')
                #del rows[:] clears the existing list, which means anywhere it's referenced will become an empty list.
                del rows[:]

            print('deleting duplicates')
            #https://docs.aws.amazon.com/redshift/latest/dg/c_redshift-sql-implementated-differently.html
            #"""allow the string to contain line breaks.
            #gives hist_id based on id and row number. 
            #Subquery ROW_NUMBER guarantee a single row with unique hist-id.
            #PARTITION BY clause divides the result set into partitions. The ROW_NUMBER() function is applied to each partition separately and reinitialized the row number for each partition.
            #If id is duplicated hist_id will be duplicated, too. T.RowNumber >1 and rows would be deleted.
            delete_query = """delete from %s WHERE hist_id IN
                                (SELECT hist_id
                                FROM (SELECT hist_id,
                                ROW_NUMBER() OVER (partition BY id ORDER BY hist_id) AS RowNumber
                                FROM %s) AS T
                                WHERE T.RowNumber > 1); """ % (self.table_name, self.table_name)
            self.cur2.execute(delete_query)
            self.conn2.commit()

        except Exception as e:
            print("there is an error in proc method: " + str(e))


    def write_data(self, cursor, connection, to_db_list, id_tag=None, update_string=None, on_conflict=False):
        """
        :param to_db_list: list of lists
        :param table_name: str name
        :param id_tag: primary key
        :param update_string: list of columns
        :param on_conflict: False by default
        :return: None
        """
        #converts %s,%s,%s,%s to (%s,%s,%s,%s). Ignores hist_id.
        signs = '(' + ('%s,' * len(to_db_list[0]))[:-1] + ')'
        

        try:
            args_str = b','.join(cursor.mogrify(signs, x) for x in to_db_list)
            args_str = args_str.decode()
            insert_statement = """INSERT INTO %s VALUES """ % self.table_name
            conflict_statement = """ ON CONFLICT DO NOTHING"""
            if on_conflict:
                #ON CONFLICT DO UPDATE - when script inserts a new row into the table, PostgreSQL will update the row if it already exists, otherwise, PostgreSQL inserts the new row. In our case ON CONFLICT will do nothing.
                conflict_statement = """ ON CONFLICT ("{0}") DO UPDATE SET {1};""".format(id_tag, update_string)
            cursor.execute(insert_statement + args_str)  # + conflict_statement)
            connection.commit()
        except Exception as e:
            print(e)


a = DatabaseRequest()
start_time = time.time()
a.proc()
print("end %.2f seconds" % (time.time() - start_time))
